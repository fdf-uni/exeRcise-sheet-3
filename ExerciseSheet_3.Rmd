---
title: "Exercise #3"
subtitle: "Fortgeschrittene Statistische Software für NF"
# Redact author name for privacy
author: "`r xfun::file_string('author.txt')`"
date: "`r Sys.Date()`"
output: distill::distill_article
---

## General Remarks

-   You can submit your solutions in teams of up to 3 students.
-   Include all your team-member's names and student numbers
    (Martrikelnummern) in the `authors` field.
-   Please use the exercise template document to work on and submit your
    results.
-   Use a level 2 heading for each new exercise and answer each subtask
    next to it's bullet point or use a new level 3 heading if you want.
-   Always render the R code for your solutions and make sure to include
    the resulting data in your rendered document.
    -   Make sure to not print more than 10 rows of data (unless
        specifically instructed to).
-   Always submit both the rendered document(s) as well as your source
    Rmarkdown document. Submit the files separately on moodle, **not**
    as a zip archive.

## Exercise 1: Initializing git (4 Points)

For this whole exercise sheet we will be tracking all our changes to it
in git.

a)  Start by initializing a new R project with git support, called
    `2024-exeRcise-sheet-3`. If you forgot how to do this, you can
    follow this
    [guide](https://malikaihle.github.io/Introduction-RStudio-Git-GitHub/rstudio_project.html).
b)  Commit the files generated by Rstudio.
c)  For all of the following tasks in this exercise sheet we ask you to
    always commit your changes after finishing each subtask e.g. create
    a commit after task *1d*, *1e* etc.

> Note: This applies only to answers that have text or code as their
> answer. If you complete tasks in a different order or forget to commit
> one, this is no problem. If you change your answers you can just
> create multiple commits to track the changes.

d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)
    
    **Strengths:**
    - Git is extremely fast. This is for example due to it being written in `C`,
      a very fast, low level language or it running mostly locally so it isn't
      being slowed down by having to (always) communicate with a centralized
      server.
    - Git is free and open-source (FOSS) software licensed under the GPLv2.
      Apart from increasing transparency this also makes it (and its source code)
      available to many people which also ensures that bugs are not only
      recognized but also fixed very fast resulting in it being highly reliable
      software.
    
    (Note that Git also comes with many other advantages that a version control
    system generally provides like being able to track changes in an efficient
    way. However, in the above we focused on strengths which Git has over other
    SCM tools.)
    
    **Weaknesses:**
    - Git has a rather steep learning curve. Especially for new users it can be
      a challenge to get started with Git.
      This is perhaps further amplified by there not being a native GUI (although
      there are many good third-party ones) such that some users might have to
      interact with the command line for the first time when learning how to use
      Git.
    - Since Git was mostly designed for use with text files (to be precise, 
      source code of the Linux kernel), it can struggle with binary and media
      files by using up a lot of storage.
      However, with solutions like `git-lfs` or `git-annex` and storage costs
      continuing to drop, this weakness becomes less and less severe.
      
e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g. the HTML page. Ignore these
    files, as we only want to track the source files themselves.

## Exercise 2: Putting your Repository on GitHub (3.5 Points)

For this task you will upload your solution to GitHub.

a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below:
    
    <center>https://github.com/fdf-uni/exeRcise-sheet-3</center>
    
b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.

## Exercise 3: Baby-Names in Munich (3.5 Points)

Download the latest open datasets on given names ("Vornamen") from the
open data repository of the city of Munich for the years `2023` and
`2022`.

Link: <https://opendata.muenchen.de/dataset/vornamen-von-neugeborenen>

a)  Download the data for both years and track it in git. For small
    datasets like these adding them to git is not a problem.
    
    We stored the datasets in a new directory called `data`.
    Although they're small, we still used `git-lsf` as follows:
    ```bash
    git lfs install
    git lfs track "*.csv"
    git add .gitattributes
    git add data
    ```
    Then we committed the changes.

b)  Load the data for both years into R. Check the type of the count
    variable ("Anzahl") and look into the data to determine why it is
    not numeric? Fix the problem in an appropriate manner, it is OK if
    some of the counts are inaccurate because of this. Explain your
    solution and the repercussions.
    
    We first load the datasets into `R`.
    ```{r}
    # Load the tidyverse
    library(tidyverse)
    
    # Load datasets (and clean up column names)
    names22 <- janitor::clean_names(read_csv(
      file.path("data", "given-names-munich-2022.csv"),
      show_col_types = FALSE
    ))
    names23 <- janitor::clean_names(read_csv(
      file.path("data", "given-names-munich-2023.csv"),
      show_col_types = FALSE
    ))
    ```
    
    We now check the type of the specified column.
    ```{r}
    typeof(names22$anzahl)
    typeof(names23$anzahl)
    ```
    
    In both cases, the column has been imported as a character.
    Inspection of its values shows why:
    ```{r}
    check_why_not_numeric <- function(data_set){
      # Filter all observations which contain non-numeric characters
      data_set %>% filter(str_detect(anzahl, "[^\\d]")) %>%
        # Get the attained values
        select(anzahl) %>% unique()
    }
    check_why_not_numeric(names22)
    check_why_not_numeric(names23)
    ```
    One sees that names which ocurred less than 4 times were all grouped together
    under the label "4 oder weniger" which (obviously) couldn't be interpreted
    as a number.
    
    We fix this problem by generating random samples according to
    [**Benford's law**](https://en.wikipedia.org/wiki/Benford's_law)
    (or rather its generalization to number systems of other bases than $10$,
    in this case $5$) for the observations in which the count variable has value
    "4 oder weniger".
    This of course also doesn't guarantee accuracy of the generated data since
    the distribution of given names might still be completely different, however
    it at least seems better than the following (and probably also most other)
    alternatives:
    - Use a normal distribution instead of the one from Benford's law.  
      (**Disadvantage**: Isn't really common for distribution of _digits_ in
      real-life sets of numerical data.)
    - Set all values to the average of all $4$ possible values, i.e.
      $\frac{5}{2}$ (since $\frac{1+2+3+4}{4}=\frac{10}{4}=\frac{5}{2}$).  
      (**Disadvantage**: In the end pretty similar to the one before.)
    - Set all values to maximal possible one, i.e. $4$.  
      (**Disadvantage**: Although this might seem like a good idea when one is
      interested in upper bounds and not worried about overcounting, this doesn't
      seem like the best choice with regards to the upcoming exercises, since we
      for example want to compare the number of births over the two years.)
    - Set all values to the minimal possible one, i.e. $1$. (Note that it isn't
      zero since we can expect that names which weren't given at all aren't
      included in the dataset.)  
      (**Disadvantage**: This might be of interest if one for example is
      interested in the, say, $50$ most popular given names. However for getting
      an estimate of births like in the next exercise, this is obviously
      horrible.)
    - Set all values to `NA`.  
      (**Disadvantage**: More or less the same as the one before if not even
      worse.)
    
    ```{r}
    # Create samples of given length according to Benford's law in base b
    # (we only need b=5 and n=1, but keep it like this for generality/fun).
    # The formula for the probability is from the above linked Wikipedia article.
    benf <- function(b, n){
      sample(1:(b-1), n, replace=TRUE, prob=log(1+1/(1:(b-1)), b))
    }
    
    new_anzahl <- function(data_set){
      # Ensure creation of random number for every row by using `rowwise()`
      data_set %>% rowwise() %>% 
        mutate(
          # Either replace by random value or turn into integer
          anzahl = if_else(
            anzahl == "4 oder weniger",
            benf(5,1),
            # We suppress warnings since they're only signaled due to values
            # which we don't use anyways being turned into NA's.
            suppressWarnings(as.integer(anzahl))
          )
        )
    }
    
    # Update `anzahl` column in both datasets using above function
    names22 <- new_anzahl(names22)
    names23 <- new_anzahl(names23)
    ```

c)  Calculate the total number of babies born in Munich in 2022
    and 2023. Which year had the bigger baby-boom?
    
    Assuming that our assumption from Exercise 1b) isn't too far away from
    reality we can calculate the total number of babies born in Munich in 2022
    and 2023, respectively, as follows:
    ```{r}
    sum(names22$anzahl)
    sum(names23$anzahl)
    ```
    Here we simply summed over all counts of names.
    Since compared to 2022, $`r sum(names22$anzahl) - sum(names23$anzahl)`$ less
    babies were born in 2023, we can say that (under our assumptions) 2022 had
    the bigger baby-boom.

d)  Add a new column `year` to both datasets which holds the correct
    year for each.
    
    We can simply proceed as follows by using `mutate()`:
    ```{r}
    names22 <- names22 %>% mutate(year = 2022)
    names23 <- names23 %>% mutate(year = 2023)
    ```
    
e)  Combine both datasets into one using `bind_rows()`.

    ```{r}
    names_combined <- bind_rows(names22, names23)
    ```

f)  Combine the counts for same names to determine the most popular
    names across both years. Print out the top 10 names in a nicely
    formatted table for both years. Include a table caption.

## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
b)  Download the dataset and track it in git.
c)  Put the name / title of the dataset and a link to it below.

-   Dataset Name: ...
-   Link: <https://github.com/owid/owid-datasets/>...

d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
e)  Use R to answer your chosen question.
f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.

## Final Note

Make sure to push all your commits and changes to GitHub before
submittining the exercise sheet.
